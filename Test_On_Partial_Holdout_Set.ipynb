{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wmezadev/CSE-450-TEAM-4/blob/luke%2Fpartial-holdout-set/Test_On_Partial_Holdout_Set.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StiU5QcPPxqQ"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXopygBsw2j_"
      },
      "source": [
        "Initial setup\n",
        "\n",
        "TODO: We need to merge training2.zip with training1.zip, by now, all the script is using only training1.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF7USssdNuDh",
        "outputId": "fe9c5e8a-9a75-41d8-dc12-4b1891fc21da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39209\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# delete the training folder if it was there from a previous run\n",
        "if not os.path.exists('training'):\n",
        "  # URLs for the datasets\n",
        "  dataset_url_1 = \"https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/roadsigns/training1.zip\"\n",
        "  dataset_url_2 = \"https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/roadsigns/training2.zip\"\n",
        "\n",
        "  # Download the ZIP files\n",
        "  zip_file_1, _ = urllib.request.urlretrieve(dataset_url_1)\n",
        "  zip_file_2, _ = urllib.request.urlretrieve(dataset_url_2)\n",
        "\n",
        "  # Extract the contents of training1.zip\n",
        "  with zipfile.ZipFile(zip_file_1, 'r') as zip_ref:\n",
        "      zip_ref.extractall()\n",
        "\n",
        "  # Extract the contents of training2.zip\n",
        "  with zipfile.ZipFile(zip_file_2, 'r') as zip_ref:\n",
        "      zip_ref.extractall()\n",
        "\n",
        "  # Merge training1 and training2 folders\n",
        "  training1 = os.listdir('training1')\n",
        "  training2 = os.listdir('training2')\n",
        "\n",
        "  for item in training1:\n",
        "    source_item = os.path.join('training1', item)\n",
        "\n",
        "    destination_item = os.path.join('training', item)\n",
        "\n",
        "    shutil.copytree(source_item, destination_item)\n",
        "\n",
        "  for item in training2:\n",
        "    source_item = os.path.join('training2', item)\n",
        "\n",
        "    destination_item = os.path.join('training', item)\n",
        "\n",
        "    if os.path.isfile(source_item):\n",
        "        shutil.copy2(source_item, destination_item)\n",
        "    elif os.path.isdir(source_item):\n",
        "        shutil.copytree(source_item, destination_item)\n",
        "\n",
        "  # clean up\n",
        "  os.remove(zip_file_1)\n",
        "  os.remove(zip_file_2)\n",
        "  shutil.rmtree('training1')\n",
        "  shutil.rmtree('training2')\n",
        "\n",
        "# Path to the merged dataset directory\n",
        "data_dir = pathlib.Path(\"training\")\n",
        "\n",
        "# our learning rates/sizes\n",
        "batch_size = 32\n",
        "img_height = 100\n",
        "img_width = 100\n",
        "\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz6fChHIxBli"
      },
      "source": [
        "Creates the train, and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnGBwGVZPyyh",
        "outputId": "002a020f-0caf-4db4-856e-5d6ba2fe6c15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 39209 files belonging to 43 classes.\n",
            "Using 31368 files for training.\n",
            "Found 39209 files belonging to 43 classes.\n",
            "Using 7841 files for validation.\n"
          ]
        }
      ],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjvNAFQJxYX2"
      },
      "source": [
        "Print some images so we have an idea of what we are working with"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mbTae6lrt6N"
      },
      "outputs": [],
      "source": [
        "class_names = []\n",
        "\n",
        "for name in train_ds.class_names:\n",
        "  if name[-1] == '0':\n",
        "    class_names.append(0)\n",
        "  else:\n",
        "    class_names.append(int(name.strip('0')))\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy8Ukxd-xtZA"
      },
      "source": [
        "This part is just for performance improvement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ysgMj9wsPNc"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBgzJ2DQxzdl"
      },
      "source": [
        "Actual Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVSfaqgKPzE2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31783d9f-3a97-4e78-abe8-9f88e5b65994"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "981/981 [==============================] - 45s 16ms/step - loss: 1.5795 - accuracy: 0.5201 - val_loss: 0.7269 - val_accuracy: 0.7697\n",
            "Epoch 2/15\n",
            "981/981 [==============================] - 11s 12ms/step - loss: 0.5103 - accuracy: 0.8386 - val_loss: 0.3004 - val_accuracy: 0.9066\n",
            "Epoch 3/15\n",
            "981/981 [==============================] - 11s 12ms/step - loss: 0.3151 - accuracy: 0.8999 - val_loss: 0.1771 - val_accuracy: 0.9464\n",
            "Epoch 4/15\n",
            "981/981 [==============================] - 12s 12ms/step - loss: 0.2453 - accuracy: 0.9229 - val_loss: 0.2031 - val_accuracy: 0.9393\n",
            "Epoch 5/15\n",
            "307/981 [========>.....................] - ETA: 7s - loss: 0.1931 - accuracy: 0.9376"
          ]
        }
      ],
      "source": [
        "num_classes = len(class_names)\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.RandomFlip(\"horizontal\",\n",
        "    input_shape=(img_height, img_width, 3)),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "  ]\n",
        ")\n",
        "\n",
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.Rescaling(1./255),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes, name=\"outputs\")\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "epochs=15\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoLb2FuTx6R-"
      },
      "source": [
        "Visual Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNXd_EoCjj7L"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDc0xuoZs3DK"
      },
      "source": [
        "## Testing the model\n",
        "Once you have built and trained your model, the next step is to run the test images through it and see how well your model does at making predictions for images it has never seen before.\n",
        "\n",
        "Since loading these images and formatting them for the model can be tricky, you may find the following code useful. This code only uses your model to predict the class label for a given image. You'll still need to compare those predictions to the \"ground truth\" class labels in `test_classes_partial.csv` to evaluate how well the model does.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "test_dir = '/content/'\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        classes=['test_partial'],\n",
        "        target_size=image_size,\n",
        "        class_mode='sparse',\n",
        "        shuffle=False)\n",
        "probabilities = model.predict(test_generator)\n",
        "predictions = [np.argmax(probas) for probas in probabilities]\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGPQfCX9G3pV"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "if not os.path.exists('test_partial'):\n",
        "  test_url = 'https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/roadsigns/test_partial.zip'\n",
        "\n",
        "  # Download the ZIP file\n",
        "  test_files, _ = urllib.request.urlretrieve(test_url)\n",
        "\n",
        "  # Extract the contents of test_partial.zip\n",
        "  with zipfile.ZipFile(test_files, 'r') as zip_ref:\n",
        "      zip_ref.extractall()\n",
        "\n",
        "test_partial_dir = os.listdir('test_partial')\n",
        "test_partial_dir.sort()\n",
        "y_pred=[]\n",
        "\n",
        "for index in range(len(test_partial_dir)):\n",
        "  dir = os.path.join('test_partial', test_partial_dir[index])\n",
        "  # print(dir)\n",
        "\n",
        "  img = tf.keras.utils.load_img(\n",
        "      dir, target_size=(img_height, img_width)\n",
        "  )\n",
        "  img_array = tf.keras.utils.img_to_array(img)\n",
        "  img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "  predictions = model.predict(img_array, verbose=0)\n",
        "  score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "  y_pred.append(class_names[np.argmax(score)])\n",
        "  # print(\n",
        "  #     \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "  #     .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        "  # )\n",
        "\n",
        "ground_truth = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/roadsigns/test_classes_partial.csv')\n",
        "y_true = ground_truth['ClassId'].values\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = np.sum(y_pred == y_true) / len(y_true)\n",
        "print(f'Accuracy on test set: {accuracy}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dodPABZ-Yz-6"
      },
      "source": [
        "##Partial Hold out Dataset\n",
        "You're given the answers to the first 200 images in the hold out dataset.\n",
        "\n",
        "Once you have predictions for the partial holdout dataset, you'll need to compare those predictions against the \"ground truth\" class labels in `test_classes_partial.csv` to evaluate how well the model does.\n",
        "\n",
        "Make sure to use the insights gained from the partial hold out dataset in your executive summary.\n",
        "\n",
        "Once you feel confident, you will need to predict for the full test dataset using the following code, and submit your csv file:\n",
        "\n",
        "```\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "test_dir = '/content/'\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        classes=['test'],\n",
        "        target_size=image_size,\n",
        "        class_mode='sparse',\n",
        "        shuffle=False)\n",
        "probabilities = model.predict(test_generator)\n",
        "predictions = [np.argmax(probas) for probas in probabilities]\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}